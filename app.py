import streamlit as st
import docx
from docx.shared import Pt, Inches
from docx.oxml.ns import qn
import random
import io
import pandas as pd
import time
import base64
from PIL import Image
from streamlit_cropper import st_cropper 

import smart_importer
import firebase_db

st.set_page_config(page_title="ç‰©ç†é¡Œåº«ç³»çµ± (Pro)", layout="wide", page_icon="ğŸ§²")

# ==========================================
# è³‡æ–™çµæ§‹èˆ‡ç‹€æ…‹åˆå§‹åŒ–
# ==========================================
class Question:
    def __init__(self, q_type, content, options=None, answer=None, original_id=0, image_data=None, 
                 source="ä¸€èˆ¬è©¦é¡Œ", chapter="æœªåˆ†é¡", unit="", db_id=None, 
                 parent_id=None, is_group_parent=False, sub_questions=None):
        self.id = db_id if db_id else str(int(time.time()*1000)) + str(random.randint(0, 999))
        self.type = q_type 
        self.source = source
        self.chapter = chapter
        self.unit = unit
        self.content = content
        self.options = options if options else []
        self.answer = answer
        self.image_data = image_data 
        
        self.parent_id = parent_id 
        self.is_group_parent = is_group_parent 
        self.sub_questions = sub_questions if sub_questions else [] 

    def to_dict(self):
        img_str = None
        if self.image_data:
            img_str = base64.b64encode(self.image_data).decode('utf-8')
        
        subs = [q.to_dict() for q in self.sub_questions] if self.sub_questions else []

        return {
            "id": self.id,
            "type": self.type,
            "source": self.source,
            "chapter": self.chapter,
            "content": self.content,
            "options": self.options,
            "answer": self.answer,
            "image_data_b64": img_str,
            "parent_id": self.parent_id,
            "is_group_parent": self.is_group_parent,
            "sub_questions": subs
        }

    @staticmethod
    def from_dict(data):
        img_bytes = None
        if data.get("image_data_b64"):
            try:
                img_bytes = base64.b64decode(data["image_data_b64"])
            except: pass
            
        q = Question(
            q_type=data.get("type", "Single"),
            content=data.get("content", ""),
            options=data.get("options", []),
            answer=data.get("answer", ""),
            original_id=0,
            image_data=img_bytes,
            source=data.get("source", ""),
            chapter=data.get("chapter", "æœªåˆ†é¡"),
            db_id=data.get("id"),
            parent_id=data.get("parent_id"),
            is_group_parent=data.get("is_group_parent", False)
        )
        
        if data.get("sub_questions"):
            q.sub_questions = [Question.from_dict(sub) for sub in data["sub_questions"]]
            
        return q

# === Session State åˆå§‹åŒ– ===
if 'question_pool' not in st.session_state:
    st.session_state['question_pool'] = []
    cloud_data = firebase_db.load_questions_from_cloud()
    if cloud_data:
        st.session_state['question_pool'] = [Question.from_dict(d) for d in cloud_data]

if 'file_queue' not in st.session_state:
    st.session_state['file_queue'] = {}

# ==========================================
# å·¥å…·å‡½å¼
# ==========================================
def generate_word_files(selected_questions):
    exam_doc = docx.Document()
    ans_doc = docx.Document()
    style = exam_doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.font.size = Pt(12)
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'æ¨™æ¥·é«”')
    
    exam_doc.add_heading('ç‰©ç†ç§‘ è©¦é¡Œå·', 0)
    ans_doc.add_heading('ç‰©ç†ç§‘ ç­”æ¡ˆå·', 0)
    
    q_counter = 1
    
    def write_single_question(doc, q, idx_str):
        p = doc.add_paragraph()
        type_label = {'Single': 'ã€å–®é¸ã€‘', 'Multi': 'ã€å¤šé¸ã€‘', 'Fill': 'ã€å¡«å……ã€‘', 'Group': 'ã€é¡Œçµ„ã€‘'}.get(q.type, '')
        src_label = f"[{q.source}] " if q.source and not q.parent_id else "" 
        
        runner = p.add_run(f"{idx_str}. {src_label}{type_label} {q.content.strip()}")
        runner.bold = True
        
        if q.image_data:
            try:
                img_p = doc.add_paragraph()
                run = img_p.add_run()
                run.add_picture(io.BytesIO(q.image_data), width=Inches(2.5))
            except: pass

        if q.type in ['Single', 'Multi'] and q.options:
            opts = q.options
            max_len = max([len(str(o)) for o in opts]) if opts else 0
            if max_len < 10 and len(opts) > 0:
                doc.add_paragraph("ã€€ã€€".join(opts))
            elif max_len < 25 and len(opts) > 0 and len(opts) % 2 == 0:
                table = doc.add_table(rows=(len(opts) // 2), cols=2)
                table.autofit = True
                for i, opt in enumerate(opts):
                    table.cell(i // 2, i % 2).text = opt
                doc.add_paragraph("")
            else:
                for opt in opts:
                    doc.add_paragraph(f"{opt}")
        elif q.type == 'Fill':
            doc.add_paragraph("ç­”ï¼š______________________")
        doc.add_paragraph("") 

    for q in selected_questions:
        if q.is_group_parent:
            write_single_question(exam_doc, q, f"{q_counter}-{q_counter + len(q.sub_questions) - 1} ç‚ºé¡Œçµ„")
            for sub_q in q.sub_questions:
                write_single_question(exam_doc, sub_q, str(q_counter))
                ans_p = ans_doc.add_paragraph()
                ans_p.add_run(f"{q_counter}. {sub_q.answer}")
                q_counter += 1
        else:
            write_single_question(exam_doc, q, str(q_counter))
            ans_p = ans_doc.add_paragraph()
            ans_p.add_run(f"{q_counter}. {q.answer}")
            q_counter += 1
        
    exam_io = io.BytesIO()
    ans_io = io.BytesIO()
    exam_doc.save(exam_io)
    ans_doc.save(ans_io)
    exam_io.seek(0)
    ans_io.seek(0)
    return exam_io, ans_io

def process_single_file(filename, api_key):
    """è™•ç†å–®ä¸€æª”æ¡ˆçš„ AI è¾¨è­˜"""
    if filename not in st.session_state['file_queue']: return
    
    info = st.session_state['file_queue'][filename]
    info['status'] = 'processing'
    
    with st.spinner(f"æ­£åœ¨åˆ†æ {filename}..."):
        res = smart_importer.parse_with_gemini(info['data'], info['type'], api_key)
    
    if isinstance(res, dict) and "error" in res:
        info['status'] = 'error'
        info['error_msg'] = res['error']
        st.error(f"{filename} è¾¨è­˜å¤±æ•—: {res['error']}")
    else:
        info['status'] = 'done'
        info['result'] = res
        st.success(f"{filename} è¾¨è­˜å®Œæˆï¼")
        
    st.rerun()

# ==========================================
# ä»‹é¢
# ==========================================
st.title("ğŸ§² ç‰©ç†é¡Œåº«ç³»çµ± Pro")

with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("Gemini API Key", type="password")
    st.divider()
    st.metric("é¡Œåº«ç¸½æ•¸", len(st.session_state['question_pool']))
    
    if st.button("å¼·åˆ¶å„²å­˜è‡³é›²ç«¯"):
        db = firebase_db.get_db()
        if db:
            for q in st.session_state['question_pool']:
                firebase_db.save_question_to_cloud(q.to_dict())
            st.success("å„²å­˜å®Œæˆï¼")

tab1, tab2, tab3 = st.tabs(["ğŸ§  æª”æ¡ˆç®¡ç†èˆ‡è¾¨è­˜", "ğŸ“ åŒ¯å…¥æ ¡å°", "ğŸ“š é¡Œåº«ç®¡ç†"])

# === Tab 1: æª”æ¡ˆç®¡ç†èˆ‡è¾¨è­˜ ===
with tab1:
    # 1. ä¸Šå‚³å€
    st.markdown("### ğŸ“¤ ä¸Šå‚³æª”æ¡ˆ (æ‰¹æ¬¡)")
    uploaded_files = st.file_uploader("æ”¯æ´ .pdf, .docx", type=['pdf', 'docx'], accept_multiple_files=True)
    
    if uploaded_files:
        new_count = 0
        for f in uploaded_files:
            if f.name not in st.session_state['file_queue']:
                st.session_state['file_queue'][f.name] = {
                    "status": "uploaded", 
                    "data": f.read(),
                    "type": f.name.split('.')[-1].lower(),
                    "result": [],
                    "error_msg": "",
                    "source_tag": "æœªåˆ†é¡" # é è¨­æ¨™ç±¤
                }
                new_count += 1
        if new_count > 0:
            st.toast(f"å·²åŠ å…¥ {new_count} å€‹æ–°æª”æ¡ˆ", icon="ğŸ“„")

    st.divider()
    
    # 2. æª”æ¡ˆåˆ—è¡¨ (åˆ†å±¤é¡¯ç¤º)
    
    # åˆ†é¡æª”æ¡ˆç‹€æ…‹
    queue = st.session_state['file_queue']
    imported_files = {} # {source_tag: [filename, ...]}
    ready_files = []    # [filename]
    pending_files = []  # [filename] (uploaded or error)
    
    # ä¿æŒé †åº (Python 3.7+ dict is ordered)
    for fname, info in queue.items():
        if info['status'] == 'imported':
            tag = info.get('source_tag', 'æœªåˆ†é¡')
            if tag not in imported_files: imported_files[tag] = []
            imported_files[tag].append(fname)
        elif info['status'] == 'done':
            ready_files.append(fname)
        else: # uploaded, processing, error
            pending_files.append(fname)

    # 2.1 å·²åŒ¯å…¥å€ (åˆ†å±¤)
    st.subheader("ğŸ“š å·²åŒ¯å…¥æª”æ¡ˆåº«")
    if not imported_files:
        st.caption("å°šç„¡å·²åŒ¯å…¥çš„æª”æ¡ˆ")
    else:
        for tag, fnames in imported_files.items():
            with st.expander(f"ğŸ“ {tag} ({len(fnames)} ä»½è©¦å·)"):
                for fname in fnames:
                    col_f1, col_f2 = st.columns([4, 1])
                    col_f1.text(f"ğŸ“„ {fname}")
                    if col_f2.button("ç§»é™¤", key=f"del_imp_{fname}"):
                        del st.session_state['file_queue'][fname]
                        st.rerun()

    st.divider()

    # 2.2 å¾…ç·¨è¼¯å€
    st.subheader("âœï¸ å¾…åŒ¯å…¥/ç·¨è¼¯ (è¾¨è­˜å®Œæˆ)")
    if not ready_files:
        st.caption("å°šç„¡ç­‰å¾…ç·¨è¼¯çš„æª”æ¡ˆ")
    else:
        for fname in ready_files:
            info = queue[fname]
            with st.container():
                c1, c2, c3 = st.columns([3, 2, 1])
                c1.markdown(f"**âœ… {fname}** ({len(info['result'])} é¡Œ)")
                c2.info("è«‹è‡³ã€ŒåŒ¯å…¥æ ¡å°ã€åˆ†é é€²è¡Œç·¨è¼¯")
                if c3.button("ğŸ—‘ï¸", key=f"del_rdy_{fname}"):
                    del st.session_state['file_queue'][fname]
                    st.rerun()
            st.divider()

    st.divider()

    # 2.3 å¾…è¾¨è­˜å€ (æœ€ä¸‹æ–¹ï¼Œå„ªå…ˆè™•ç†)
    st.subheader("â³ å¾…è¾¨è­˜æª”æ¡ˆ (éœ€åŸ·è¡Œ AI)")
    if not pending_files:
        st.info("ç›®å‰æ²’æœ‰ç­‰å¾…è¾¨è­˜çš„æª”æ¡ˆã€‚")
    else:
        # æä¾›ä¸€éµå…¨éƒ¨åŸ·è¡Œ
        if st.button("ğŸš€ å…¨éƒ¨åŸ·è¡Œè¾¨è­˜"):
            if not api_key:
                st.error("è«‹è¼¸å…¥ API Key")
            else:
                progress_bar = st.progress(0)
                for idx, fname in enumerate(pending_files):
                    process_single_file(fname, api_key) # é€™è£¡æœƒ rerunï¼Œæ‰€ä»¥å…¶å¯¦åªæœƒè·‘ç¬¬ä¸€å€‹
                    # è‹¥è¦é€£çºŒè·‘ï¼Œéœ€ä¿®æ”¹ process_single_file ä¸ rerunï¼Œæ”¹ç‚ºè¿´åœˆæ§åˆ¶
                    # ä½†ç‚ºäº†ç°¡å–®èˆ‡ç©©å®šï¼Œå»ºè­°ä½¿ç”¨è€…ä¸€å€‹å€‹é»ï¼Œæˆ–æ­¤è™•ç°¡å–®è™•ç†
                st.rerun()

        for fname in pending_files:
            info = queue[fname]
            with st.container():
                c1, c2, c3 = st.columns([3, 2, 1])
                
                status_display = "ç­‰å¾…ä¸­"
                if info['status'] == 'processing': status_display = "ğŸ”„ åˆ†æä¸­..."
                elif info['status'] == 'error': status_display = f"âŒ å¤±æ•—: {info['error_msg']}"
                
                c1.markdown(f"**ğŸ“„ {fname}**")
                c2.caption(status_display)
                
                if c3.button("â–¶ï¸ åŸ·è¡Œ", key=f"run_{fname}", disabled=(info['status']=='processing')):
                    if not api_key:
                        st.error("è«‹è¼¸å…¥ API Key")
                    else:
                        process_single_file(fname, api_key)
            st.divider()

# === Tab 2: åŒ¯å…¥æ ¡å° ===
with tab2:
    st.subheader("åŒ¯å…¥æ ¡å°èˆ‡æˆªåœ–")
    
    ready_files = [f for f, info in st.session_state['file_queue'].items() if info['status'] == 'done']
    
    if not ready_files:
        st.warning("æ²’æœ‰å·²å®Œæˆè¾¨è­˜çš„æª”æ¡ˆã€‚è«‹å…ˆè‡³ Tab 1 ä¸Šå‚³ä¸¦åŸ·è¡Œã€‚")
    else:
        selected_file = st.selectbox("é¸æ“‡è¦è™•ç†çš„æª”æ¡ˆ", ready_files)
        file_info = st.session_state['file_queue'][selected_file]
        candidates = file_info['result']
        
        st.markdown(f"**æ­£åœ¨ç·¨è¼¯ï¼š{selected_file} (å…± {len(candidates)} é¡Œ)**")
        
        # ä¾†æºæ¨™ç±¤è¨­å®š
        col_src1, col_src2 = st.columns(2)
        with col_src1:
            # é è¨­ä½¿ç”¨æª”åä½œç‚ºæ¨™ç±¤
            default_tag = selected_file.split('.')[0]
            source_tag = st.text_input("è¨­å®šæ­¤æ‰¹è©¦å·ä¾†æºæ¨™ç±¤", value=default_tag, help="æ­¤æ¨™ç±¤å°‡ç”¨æ–¼åˆ†é¡ç®¡ç†æª”æ¡ˆ")
        
        st.divider()
        
        # é¡Œç›®ç·¨è¼¯è¿´åœˆ
        for i, cand in enumerate(candidates):
            with st.container():
                st.markdown(f"**ç¬¬ {cand.number} é¡Œ**")
                c1, c2 = st.columns([1, 1])
                
                with c1:
                    new_content = st.text_area(f"é¡Œç›®å…§å®¹ #{i}", cand.content, height=100, key=f"{selected_file}_c_{i}")
                    cand.content = new_content
                    
                    opts_text = "\n".join(cand.options)
                    new_opts = st.text_area(f"é¸é … #{i}", opts_text, height=80, key=f"{selected_file}_o_{i}")
                    cand.options = new_opts.split('\n') if new_opts else []
                    
                    type_idx = ["Single", "Multi", "Fill"].index(cand.q_type) if cand.q_type in ["Single", "Multi", "Fill"] else 0
                    cand.q_type = st.selectbox(f"é¡Œå‹ #{i}", ["Single", "Multi", "Fill"], index=type_idx, key=f"{selected_file}_t_{i}")

                    ans_key = f"{selected_file}_ans_{i}"
                    if ans_key not in st.session_state: st.session_state[ans_key] = ""
                    st.text_input(f"ç­”æ¡ˆ (å¯ç•™ç©º) #{i}", key=ans_key)
                    
                    chap_idx = 0
                    if cand.predicted_chapter in smart_importer.PHYSICS_CHAPTERS_LIST:
                        chap_idx = smart_importer.PHYSICS_CHAPTERS_LIST.index(cand.predicted_chapter)
                    cand.predicted_chapter = st.selectbox(f"ç« ç¯€åˆ†é¡ #{i}", smart_importer.PHYSICS_CHAPTERS_LIST, index=chap_idx, key=f"{selected_file}_ch_{i}")
                    
                    if cand.image_bytes:
                        st.image(cand.image_bytes, caption="ç›®å‰é™„åœ–", width=200)
                    else:
                        st.caption("ğŸš« ç›®å‰ç„¡é™„åœ–")

                with c2:
                    if cand.ref_image_bytes:
                        st.markdown("âœ‚ï¸ **æˆªåœ–å·¥å…·**")
                        try:
                            pil_ref = Image.open(io.BytesIO(cand.ref_image_bytes))
                            cropped_img = st_cropper(
                                pil_ref, 
                                realtime_update=True, 
                                box_color='#FF0000',
                                key=f"{selected_file}_cropper_{i}",
                                aspect_ratio=None
                            )
                            col_act1, col_act2 = st.columns(2)
                            if col_act1.button(f"ğŸ“· è¨­ç‚ºé™„åœ– #{i}", key=f"{selected_file}_btn_crop_{i}"):
                                img_byte_arr = io.BytesIO()
                                cropped_img.save(img_byte_arr, format='PNG')
                                cand.image_bytes = img_byte_arr.getvalue()
                                st.success("é™„åœ–å·²æ›´æ–°")
                                st.rerun()
                            if col_act2.button(f"ğŸš« ä¸ä½¿ç”¨åœ–ç‰‡ #{i}", key=f"{selected_file}_btn_noimg_{i}"):
                                cand.image_bytes = None
                                st.success("é™„åœ–å·²ç§»é™¤")
                                st.rerun()
                        except: st.error("æˆªåœ–è¼‰å…¥å¤±æ•—")
                    else:
                        st.info("æ­¤é¡Œç„¡åƒè€ƒæˆªåœ–")
                st.divider()

        if st.button(f"âœ… ç¢ºèªåŒ¯å…¥ [{selected_file}] çš„æ‰€æœ‰é¡Œç›®", type="primary"):
            count = 0
            for i, cand in enumerate(candidates):
                ans_val = st.session_state.get(f"{selected_file}_ans_{i}", "")
                
                new_q = Question(
                    q_type=cand.q_type,
                    content=cand.content,
                    options=cand.options,
                    source=source_tag, 
                    chapter=cand.predicted_chapter,
                    image_data=cand.image_bytes,
                    answer=ans_val 
                )
                st.session_state['question_pool'].append(new_q)
                firebase_db.save_question_to_cloud(new_q.to_dict())
                count += 1
            
            st.success(f"æˆåŠŸåŒ¯å…¥ {count} é¡Œï¼")
            
            # æ›´æ–°æª”æ¡ˆç‹€æ…‹èˆ‡æ¨™ç±¤
            st.session_state['file_queue'][selected_file]['status'] = 'imported'
            st.session_state['file_queue'][selected_file]['source_tag'] = source_tag # å„²å­˜æ¨™ç±¤ä»¥ä¾¿åˆ†é¡
            st.rerun()

# === Tab 3: é¡Œåº«ç®¡ç† (åˆ†å±¤é¡¯ç¤º) ===
with tab3:
    st.subheader("é¡Œåº«ç¸½è¦½èˆ‡è©¦å·è¼¸å‡º")
    if not st.session_state['question_pool']:
        st.info("ç›®å‰æ²’æœ‰é¡Œç›®ã€‚")
    else:
        # 1. å–å¾—æ‰€æœ‰ä¾†æº
        all_sources = sorted(list(set([q.source for q in st.session_state['question_pool']])))
        
        # 2. é¡¯ç¤ºåˆ†å±¤åˆ—è¡¨
        selected_questions_for_export = []
        
        for src in all_sources:
            # ç¯©é¸è©²ä¾†æºçš„é¡Œç›®
            qs_in_src = [q for q in st.session_state['question_pool'] if q.source == src]
            
            with st.expander(f"ğŸ“ {src} ({len(qs_in_src)} é¡Œ)"):
                # è®“ä½¿ç”¨è€…é¸æ“‡æ˜¯å¦å…¨é¸é€™å€‹ä¾†æº
                if st.checkbox(f"é¸å–å…¨å¥— [{src}] é€²è¡ŒåŒ¯å‡º", key=f"sel_src_{src}"):
                    selected_questions_for_export.extend(qs_in_src)

                for i, q in enumerate(qs_in_src):
                    type_badge = {'Single': 'å–®', 'Multi': 'å¤š', 'Fill': 'å¡«', 'Group': 'é¡Œçµ„'}.get(q.type, 'æœªçŸ¥')
                    # å­é¡Œä¸é¡¯ç¤ºï¼Œå› ç‚ºæœƒè·Ÿè‘—æ¯é¡Œ
                    if q.parent_id: continue 
                    
                    st.markdown(f"**[{type_badge}] {q.content[:30]}...**")
                    
                    # ç°¡æ˜“ç·¨è¼¯æŒ‰éˆ• (è‹¥è¦è©³ç´°ç·¨è¼¯å¯é»é–‹)
                    with st.popover("ç·¨è¼¯"):
                        q.content = st.text_area("é¡Œç›®", q.content, key=f"edt_c_{q.id}")
                        q.answer = st.text_input("ç­”æ¡ˆ", q.answer, key=f"edt_a_{q.id}")
                        if st.button("å„²å­˜", key=f"save_{q.id}"):
                            firebase_db.save_question_to_cloud(q.to_dict())
                            st.rerun()
                        if st.button("åˆªé™¤", key=f"del_{q.id}", type="primary"):
                            firebase_db.delete_question_from_cloud(q.id)
                            st.rerun()
                    st.divider()

        st.divider()
        st.subheader(f"å·²é¸å– {len(selected_questions_for_export)} é¡Œæº–å‚™åŒ¯å‡º")
        if st.button("ç”Ÿæˆ Word è©¦å·"):
            f1, f2 = generate_word_files(selected_questions_for_export)
            st.download_button("ä¸‹è¼‰è©¦é¡Œå·", f1, "exam.docx")
            st.download_button("ä¸‹è¼‰ç­”æ¡ˆå·", f2, "ans.docx")
