import streamlit as st
import docx
from docx.shared import Pt, Inches
from docx.oxml.ns import qn
import random
import io
import pandas as pd
import time
import base64
import requests 
from PIL import Image
from streamlit_cropper import st_cropper 
import os
import datetime
import uuid
import json
from google.cloud import firestore
from google.cloud import storage
import google.auth 
from google.oauth2 import service_account

import smart_importer

st.set_page_config(page_title="ç‰©ç†é¡Œåº«ç³»çµ± (Pro)", layout="wide", page_icon="ğŸ§²")

# ==========================================
# é›²ç«¯è³‡æ–™åº«èˆ‡å„²å­˜æ¨¡çµ„ (å…§å»º)
# ==========================================
class CloudManager:
    def __init__(self):
        self.bucket_name = os.getenv("GCS_BUCKET_NAME", "physics-exam-assets")
        self.db = None
        self.storage_client = None
        self.has_connection = False
        self.connection_error = ""
        self.project_id = None
        self.credentials = None 

        try:
            # ç­–ç•¥ 1ï¼šç’°å¢ƒè®Šæ•¸ JSON (Cloud Run å„ªå…ˆ)
            service_account_json = os.getenv("GCP_SERVICE_ACCOUNT_JSON")
            if service_account_json:
                try:
                    service_account_json = service_account_json.strip()
                    if service_account_json.startswith("'") and service_account_json.endswith("'"):
                         service_account_json = service_account_json[1:-1]
                    
                    service_account_info = json.loads(service_account_json)
                    self.credentials = service_account.Credentials.from_service_account_info(service_account_info)
                    self.project_id = service_account_info.get("project_id")
                    
                    if not self.project_id:
                         self.project_id = os.getenv("GCP_PROJECT_ID")

                    self.db = firestore.Client(credentials=self.credentials, project=self.project_id)
                    self.storage_client = storage.Client(credentials=self.credentials, project=self.project_id)
                    self.has_connection = True
                    if self.has_connection: self._ensure_bucket_exists()
                    return
                except Exception as e:
                    print(f"ç’°å¢ƒè®Šæ•¸ JSON é€£ç·šå¤±æ•—: {e}")

            # ç­–ç•¥ 2ï¼šStreamlit Secrets (Streamlit Cloud)
            try:
                if "gcp_service_account" in st.secrets:
                    try:
                        service_account_info = st.secrets["gcp_service_account"]
                        self.credentials = service_account.Credentials.from_service_account_info(service_account_info)
                        
                        self.project_id = service_account_info.get("project_id")
                        self.db = firestore.Client(credentials=self.credentials, project=self.project_id)
                        self.storage_client = storage.Client(credentials=self.credentials, project=self.project_id)
                        self.has_connection = True
                        if self.has_connection: self._ensure_bucket_exists()
                        return 
                    except Exception as e:
                        print(f"Secrets é€£ç·šå¤±æ•—: {e}")
            except: pass

            # ç­–ç•¥ 3ï¼šè‡ªå‹•åµæ¸¬
            self.project_id = (os.getenv("GCP_PROJECT_ID") or os.getenv("GOOGLE_CLOUD_PROJECT"))
            
            if not self.project_id:
                try:
                    self.credentials, project_id_from_auth = google.auth.default()
                    if project_id_from_auth:
                        self.project_id = project_id_from_auth
                except: pass

            if self.project_id:
                if self.credentials:
                    self.db = firestore.Client(credentials=self.credentials, project=self.project_id)
                    self.storage_client = storage.Client(credentials=self.credentials, project=self.project_id)
                else:
                    self.db = firestore.Client(project=self.project_id)
                    self.storage_client = storage.Client(project=self.project_id)
                self.has_connection = True
            else:
                try:
                    self.db = firestore.Client()
                    self.storage_client = storage.Client()
                    self.has_connection = True
                except: pass
            
            if self.has_connection: self._ensure_bucket_exists()

        except Exception as e:
            self.connection_error = str(e)
            print(f"Cloud é€£ç·šåˆå§‹åŒ–å¤±æ•—: {e}")

    def _ensure_bucket_exists(self):
        if not self.storage_client: return
        try:
            target_bucket_name = self.bucket_name
            if not target_bucket_name:
                try:
                    if "GCS_BUCKET_NAME" in st.secrets:
                        target_bucket_name = st.secrets["GCS_BUCKET_NAME"]
                except: pass
            
            if target_bucket_name:
                bucket = self.storage_client.bucket(target_bucket_name)
                if not bucket.exists():
                    bucket.create(location="us-central1") 
        except: pass

    def upload_bytes(self, file_bytes, filename, folder="uploads", content_type=None):
        if not self.storage_client: return None
        try:
            target_bucket_name = self.bucket_name
            if not target_bucket_name:
                try:
                    if "GCS_BUCKET_NAME" in st.secrets:
                        target_bucket_name = st.secrets["GCS_BUCKET_NAME"]
                except: pass
            
            if not target_bucket_name:
                st.error("æœªè¨­å®š Bucket åç¨±")
                return None

            bucket = self.storage_client.bucket(target_bucket_name)
            # ä½¿ç”¨å›ºå®šæª”åé‚è¼¯æˆ–åŠ è“‹ UUID è¦–éœ€æ±‚è€Œå®šï¼Œé€™è£¡ç¶­æŒä¸è®Šä»¥ç¢ºä¿å”¯ä¸€æ€§
            unique_name = f"{folder}/{int(datetime.datetime.now().timestamp())}_{str(uuid.uuid4())[:8]}_{filename}"
            blob = bucket.blob(unique_name)
            blob.upload_from_string(file_bytes, content_type=content_type)
            
            try:
                url = blob.generate_signed_url(
                    version="v4",
                    expiration=datetime.timedelta(days=7),
                    method="GET",
                    service_account_email=self.credentials.service_account_email if hasattr(self.credentials, 'service_account_email') else None,
                    access_token=self.credentials.token if hasattr(self.credentials, 'token') else None
                )
                return url
            except:
                return blob.public_url 

        except Exception as e:
            print(f"ä¸Šå‚³å¤±æ•—: {e}")
            return None

    # --- æª”æ¡ˆåº«ç®¡ç†åŠŸèƒ½ ---
    
    # [æ–°å¢] æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
    def check_file_exists(self, filename):
        """æª¢æŸ¥ Firestore ä¸­æ˜¯å¦æœ‰åŒåæª”æ¡ˆ"""
        if not self.db: return None
        try:
            # æŸ¥è©¢ exam_files é›†åˆä¸­ filename æ¬„ä½ç­‰æ–¼ filename çš„æ–‡ä»¶
            docs = self.db.collection("exam_files").where("filename", "==", filename).limit(1).stream()
            for doc in docs:
                data = doc.to_dict()
                data['id'] = doc.id
                return data # å›å‚³å·²å­˜åœ¨çš„æª”æ¡ˆè³‡æ–™
            return None
        except Exception as e:
            print(f"æª¢æŸ¥æª”æ¡ˆå¤±æ•—: {e}")
            return None

    def save_file_record(self, file_info, overwrite_id=None):
        """å„²å­˜æˆ–æ›´æ–°æª”æ¡ˆè¨˜éŒ„"""
        if not self.db: return False
        try:
            # å¦‚æœæ˜¯è¦†è“‹ï¼Œä½¿ç”¨èˆŠ IDï¼›å¦å‰‡ç”Ÿæˆæ–° ID
            doc_id = overwrite_id if overwrite_id else str(uuid.uuid4())
            file_info["id"] = doc_id
            file_info["updated_at"] = datetime.datetime.now()
            
            self.db.collection("exam_files").document(doc_id).set(file_info)
            return True
        except Exception as e:
            st.error(f"å„²å­˜æª”æ¡ˆè¨˜éŒ„å¤±æ•—: {e}")
            return False

    def load_file_records(self):
        if not self.db: return []
        try:
            files = []
            docs = self.db.collection("exam_files").order_by("updated_at", direction=firestore.Query.DESCENDING).stream()
            for doc in docs:
                files.append(doc.to_dict())
            return files
        except Exception as e:
            st.error(f"è®€å–æª”æ¡ˆåˆ—è¡¨å¤±æ•—: {e}")
            return []

    def delete_file_record(self, file_id):
        if self.db:
            self.db.collection("exam_files").document(file_id).delete()

    def update_file_status(self, file_id, status):
        if self.db:
            self.db.collection("exam_files").document(file_id).update({"ai_status": status})

    # --- é¡Œåº«ç®¡ç†åŠŸèƒ½ ---
    def save_question(self, question_dict):
        if not self.db: return False
        try:
            if question_dict.get("image_data_b64"):
                try:
                    img_bytes = base64.b64decode(question_dict["image_data_b64"])
                    fname = f"q_{question_dict.get('id', 'unknown')}.png"
                    img_url = self.upload_bytes(img_bytes, fname, folder="question_images", content_type="image/png")
                    if img_url:
                        question_dict["image_url"] = img_url
                        del question_dict["image_data_b64"]
                except Exception as e:
                    print(f"åœ–ç‰‡è½‰å­˜å¤±æ•—: {e}")
            
            self.db.collection("questions").document(question_dict["id"]).set(question_dict)
            return True
        except Exception as e:
            st.error(f"å„²å­˜é¡Œç›®å¤±æ•—: {e}")
            return False

    def load_questions(self):
        if not self.db: return []
        try:
            questions = []
            docs = self.db.collection("questions").order_by("id").stream()
            for doc in docs:
                questions.append(doc.to_dict())
            return questions
        except Exception as e:
            st.error(f"è®€å–é¡Œåº«å¤±æ•—: {e}")
            return []

    def delete_question(self, doc_id):
        if self.db:
            self.db.collection("questions").document(doc_id).delete()

# åˆå§‹åŒ– Cloud Manager
cloud_manager = CloudManager()

# ==========================================
# è³‡æ–™çµæ§‹èˆ‡ç‹€æ…‹åˆå§‹åŒ–
# ==========================================
class Question:
    def __init__(self, q_type, content, options=None, answer=None, original_id=0, image_data=None, 
                 source="ä¸€èˆ¬è©¦é¡Œ", chapter="æœªåˆ†é¡", unit="", db_id=None, 
                 parent_id=None, is_group_parent=False, sub_questions=None, image_url=None,
                 source_file_id=None):
        self.id = db_id if db_id else str(int(time.time()*1000)) + str(random.randint(0, 999))
        self.type = q_type 
        self.source = source
        self.chapter = chapter
        self.unit = unit
        self.content = content
        self.options = options if options else []
        self.answer = answer
        self.image_data = image_data 
        self.image_url = image_url   
        
        self.parent_id = parent_id 
        self.is_group_parent = is_group_parent 
        self.sub_questions = sub_questions if sub_questions else [] 
        self.source_file_id = source_file_id

    def to_dict(self):
        img_str = None
        if self.image_data:
            img_str = base64.b64encode(self.image_data).decode('utf-8')
        
        subs = [q.to_dict() for q in self.sub_questions] if self.sub_questions else []

        return {
            "id": self.id,
            "type": self.type,
            "source": self.source,
            "chapter": self.chapter,
            "content": self.content,
            "options": self.options,
            "answer": self.answer,
            "image_data_b64": img_str, 
            "image_url": self.image_url,
            "parent_id": self.parent_id,
            "is_group_parent": self.is_group_parent,
            "sub_questions": subs,
            "source_file_id": self.source_file_id
        }

    @staticmethod
    def from_dict(data):
        img_bytes = None
        img_url = data.get("image_url")
        if data.get("image_data_b64"):
            try:
                img_bytes = base64.b64decode(data["image_data_b64"])
            except: pass
        
        q = Question(
            q_type=data.get("type", "Single"),
            content=data.get("content", ""),
            options=data.get("options", []),
            answer=data.get("answer", ""),
            original_id=0,
            image_data=img_bytes,
            image_url=img_url,
            source=data.get("source", ""),
            chapter=data.get("chapter", "æœªåˆ†é¡"),
            db_id=data.get("id"),
            parent_id=data.get("parent_id"),
            is_group_parent=data.get("is_group_parent", False),
            source_file_id=data.get("source_file_id")
        )
        if data.get("sub_questions"):
            q.sub_questions = [Question.from_dict(sub) for sub in data["sub_questions"]]
        return q

if 'question_pool' not in st.session_state:
    st.session_state['question_pool'] = []
    try:
        cloud_data = cloud_manager.load_questions()
        if cloud_data:
            st.session_state['question_pool'] = [Question.from_dict(d) for d in cloud_data]
    except: pass

if 'file_queue' not in st.session_state:
    st.session_state['file_queue'] = {}

# ==========================================
# å·¥å…·å‡½å¼
# ==========================================
def get_image_bytes(q):
    if q.image_data: return q.image_data
    if q.image_url:
        try:
            response = requests.get(q.image_url, timeout=3)
            if response.status_code == 200: return response.content
        except: return None
    return None

def generate_word_files(selected_questions):
    exam_doc = docx.Document()
    ans_doc = docx.Document()
    style = exam_doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.font.size = Pt(12)
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'æ¨™æ¥·é«”')
    
    exam_doc.add_heading('ç‰©ç†ç§‘ è©¦é¡Œå·', 0)
    ans_doc.add_heading('ç‰©ç†ç§‘ ç­”æ¡ˆå·', 0)
    
    q_counter = 1
    
    def write_single_question(doc, q, idx_str):
        p = doc.add_paragraph()
        type_label = {'Single': 'ã€å–®é¸ã€‘', 'Multi': 'ã€å¤šé¸ã€‘', 'Fill': 'ã€å¡«å……ã€‘', 'Group': 'ã€é¡Œçµ„ã€‘'}.get(q.type, '')
        src_label = f"[{q.source}] " if q.source and not q.parent_id else "" 
        
        runner = p.add_run(f"{idx_str}. {src_label}{type_label} {q.content.strip()}")
        runner.bold = True
        
        img_bytes = get_image_bytes(q)
        if img_bytes:
            try:
                img_p = doc.add_paragraph()
                run = img_p.add_run()
                run.add_picture(io.BytesIO(img_bytes), width=Inches(2.5))
            except: pass

        if q.type in ['Single', 'Multi'] and q.options:
            opts = q.options
            max_len = max([len(str(o)) for o in opts]) if opts else 0
            if max_len < 10 and len(opts) > 0:
                doc.add_paragraph("ã€€ã€€".join(opts))
            elif max_len < 25 and len(opts) > 0 and len(opts) % 2 == 0:
                table = doc.add_table(rows=(len(opts) // 2), cols=2)
                table.autofit = True
                for i, opt in enumerate(opts):
                    table.cell(i // 2, i % 2).text = opt
                doc.add_paragraph("")
            else:
                for opt in opts:
                    doc.add_paragraph(f"{opt}")
        elif q.type == 'Fill':
            doc.add_paragraph("ç­”ï¼š______________________")
        doc.add_paragraph("") 

    for q in selected_questions:
        if q.is_group_parent:
            write_single_question(exam_doc, q, f"{q_counter}-{q_counter + len(q.sub_questions) - 1} ç‚ºé¡Œçµ„")
            for sub_q in q.sub_questions:
                write_single_question(exam_doc, sub_q, str(q_counter))
                ans_p = ans_doc.add_paragraph()
                ans_p.add_run(f"{q_counter}. {sub_q.answer}")
                q_counter += 1
        else:
            write_single_question(exam_doc, q, str(q_counter))
            ans_p = ans_doc.add_paragraph()
            ans_p.add_run(f"{q_counter}. {q.answer}")
            q_counter += 1
        
    exam_io = io.BytesIO()
    ans_io = io.BytesIO()
    exam_doc.save(exam_io)
    ans_doc.save(ans_io)
    exam_io.seek(0)
    ans_io.seek(0)
    return exam_io, ans_io

def process_single_file(filename, api_key, file_id_in_db=None):
    if filename not in st.session_state['file_queue']: return
    info = st.session_state['file_queue'][filename]
    info['status'] = 'processing'
    
    with st.spinner(f"æ­£åœ¨åˆ†æ {filename}..."):
        res = smart_importer.parse_with_gemini(info['data'], info['type'], api_key)
    
    if isinstance(res, dict) and "error" in res:
        info['status'] = 'error'
        info['error_msg'] = res['error']
        st.error(f"{filename} è¾¨è­˜å¤±æ•—: {res['error']}")
    else:
        info['status'] = 'done'
        info['result'] = res
        if file_id_in_db:
            cloud_manager.update_file_status(file_id_in_db, "å·²è¾¨è­˜")
        st.success(f"{filename} è¾¨è­˜å®Œæˆï¼")
        
    st.rerun()

# ==========================================
# Interface
# ==========================================
st.title("ğŸ§² ç‰©ç†é¡Œåº«ç³»çµ± Pro (Cloud Storage)")

with st.sidebar:
    st.header("è¨­å®š")
    env_api_key = os.getenv("GOOGLE_API_KEY", "")
    api_key_input = st.text_input("Gemini API Key", value=env_api_key, type="password")
    
    if cloud_manager.has_connection:
        st.success("â˜ï¸ Cloud: å·²é€£ç·š")
        if cloud_manager.bucket_name:
            st.caption(f"Bucket: {cloud_manager.bucket_name}")
    else:
        st.warning(f"â˜ï¸ Cloud: æœªé€£ç·š")
        if cloud_manager.connection_error:
            st.caption(f"éŒ¯èª¤: {cloud_manager.connection_error}")
            if "No secrets found" in cloud_manager.connection_error:
                st.info("Secrets æœªè¨­å®šï¼Œè«‹æ”¹ç”¨ç’°å¢ƒè®Šæ•¸ GCP_SERVICE_ACCOUNT_JSON")

    st.divider()
    st.metric("é¡Œåº«ç¸½æ•¸", len(st.session_state['question_pool']))
    
    if st.button("å¼·åˆ¶å„²å­˜è‡³é›²ç«¯"):
        if cloud_manager.has_connection:
            progress_bar = st.progress(0)
            total = len(st.session_state['question_pool'])
            for i, q in enumerate(st.session_state['question_pool']):
                cloud_manager.save_question(q.to_dict())
                progress_bar.progress((i + 1) / total)
            st.success("å„²å­˜å®Œæˆï¼")

tab_files, tab_upload_process, tab_review, tab_bank = st.tabs(["ğŸ“‚ æª”æ¡ˆåº«ç®¡ç†", "ğŸ§  ä¸Šå‚³èˆ‡è¾¨è­˜", "ğŸ“ åŒ¯å…¥æ ¡å°", "ğŸ“š é¡Œåº«ç®¡ç†"])

# === Tab 1: æª”æ¡ˆåº«ç®¡ç† ===
with tab_files:
    st.subheader("å·²ä¸Šå‚³è€ƒå¤é¡Œæª”æ¡ˆåº«")
    cloud_files = cloud_manager.load_file_records()
    
    if not cloud_files:
        st.info("ç›®å‰æ²’æœ‰å·²ä¸Šå‚³çš„æª”æ¡ˆè¨˜éŒ„ã€‚è«‹è‡³ã€Œä¸Šå‚³èˆ‡è¾¨è­˜ã€åˆ†é æ–°å¢ã€‚")
    else:
        col_header1, col_header2, col_header3, col_header4, col_header5 = st.columns([2, 1, 1, 1, 2])
        col_header1.markdown("**æª”æ¡ˆåç¨±**")
        col_header2.markdown("**è€ƒè©¦é¡å‹**")
        col_header3.markdown("**å¹´åº¦**")
        col_header4.markdown("**AI ç‹€æ…‹**")
        col_header5.markdown("**æ“ä½œ**")
        st.divider()

        for f_record in cloud_files:
            c1, c2, c3, c4, c5 = st.columns([2, 1, 1, 1, 2])
            with c1:
                st.write(f"ğŸ“„ {f_record.get('filename', 'æœªçŸ¥')}")
                if f_record.get('url'):
                    st.caption(f"[ä¸‹è¼‰åŸå§‹æª”]({f_record.get('url')})")
            with c2: st.write(f_record.get('exam_type', '-'))
            with c3: st.write(f_record.get('year', '-'))
            with c4:
                status = f_record.get('ai_status', 'æœªè¾¨è­˜')
                if status == 'å·²è¾¨è­˜': st.success("å·²è¾¨è­˜")
                elif status == 'è™•ç†ä¸­': st.warning("è™•ç†ä¸­")
                else: st.info("æœªè¾¨è­˜")
            with c5:
                if st.button("AI è¾¨è­˜", key=f"ai_{f_record['id']}"):
                    fname = f_record['filename']
                    if fname not in st.session_state['file_queue']:
                        try:
                            file_url = f_record.get('url')
                            if file_url:
                                resp = requests.get(file_url)
                                if resp.status_code == 200:
                                    st.session_state['file_queue'][fname] = {
                                        "status": "uploaded", 
                                        "data": resp.content,
                                        "type": fname.split('.')[-1].lower(),
                                        "result": [],
                                        "error_msg": "",
                                        "source_tag": f"{f_record.get('exam_type','')}-{f_record.get('year','')}",
                                        "backup_url": file_url,
                                        "db_id": f_record['id']
                                    }
                                    process_single_file(fname, api_key_input, f_record['id'])
                                else: st.error("ç„¡æ³•å¾é›²ç«¯ä¸‹è¼‰æª”æ¡ˆ")
                        except Exception as e: st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")
                    else:
                        process_single_file(fname, api_key_input, f_record['id'])

                if st.button("åˆªé™¤", key=f"del_f_{f_record['id']}", type="primary"):
                    cloud_manager.delete_file_record(f_record['id'])
                    st.rerun()
            st.divider()

# === Tab 2: ä¸Šå‚³èˆ‡è¾¨è­˜ (å«é‡è¤‡æª¢æŸ¥) ===
with tab_upload_process:
    st.markdown("### ğŸ“¤ ä¸Šå‚³æ–°è€ƒå¤é¡Œ")
    
    # ä½¿ç”¨ Form ä¹‹å‰ï¼Œå…ˆä¸Šå‚³æª”æ¡ˆä»¥æª¢æŸ¥é‡è¤‡
    # ç‚ºäº†å¯¦ç¾ã€Œä¸Šå‚³å‰æª¢æŸ¥ã€ï¼Œæˆ‘å€‘ä¸èƒ½æŠŠ file_uploader æ”¾åœ¨ form è£¡é¢ï¼Œå› ç‚º form åªåœ¨ submit æ™‚å‚³é€
    # æ‰€ä»¥é€™è£¡å°‡æµç¨‹æ‹†é–‹ï¼šå…ˆä¸Šå‚³ -> æª¢æŸ¥ -> å¡«å¯«è³‡æ–™ -> ç¢ºèªå„²å­˜
    
    uploaded_files = st.file_uploader("æ”¯æ´ .pdf, .docx", type=['pdf', 'docx'], accept_multiple_files=True)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡æª”æ¡ˆ
    duplicate_files = []
    if uploaded_files:
        for f in uploaded_files:
            existing = cloud_manager.check_file_exists(f.name)
            if existing:
                duplicate_files.append((f, existing))
    
    # é¡¯ç¤ºé‡è¤‡è­¦å‘Šèˆ‡æ“ä½œé¸é …
    files_to_process = []
    if duplicate_files:
        st.warning(f"âš ï¸ ç™¼ç¾ {len(duplicate_files)} å€‹æª”åé‡è¤‡çš„æª”æ¡ˆï¼")
        
        # è®“ä½¿ç”¨è€…æ±ºå®šæ¯å€‹é‡è¤‡æª”æ¡ˆçš„è™•ç†æ–¹å¼
        overwrite_decisions = {} # {filename: True/False}
        
        for f, existing_record in duplicate_files:
            col_warn, col_opt = st.columns([3, 1])
            with col_warn:
                st.markdown(f"**{f.name}** (ä¸Šæ¬¡ä¸Šå‚³ï¼š{existing_record.get('updated_at', 'æœªçŸ¥æ™‚é–“')})")
            with col_opt:
                # é è¨­ä¸è¦†è“‹ (False)
                decision = st.radio(f"è™•ç†æ–¹å¼ ({f.name})", ["è·³é", "è¦†è“‹"], key=f"dup_{f.name}")
                if decision == "è¦†è“‹":
                    files_to_process.append((f, existing_record['id'])) # å‚³å…¥èˆŠ ID ä»¥ä¾¿æ›´æ–°
                else:
                    st.caption("å°‡ç•¥éæ­¤æª”æ¡ˆ")
    
    # åŠ å…¥éé‡è¤‡çš„æª”æ¡ˆ
    if uploaded_files:
        for f in uploaded_files:
            is_dup = False
            for dup_f, _ in duplicate_files:
                if f.name == dup_f.name:
                    is_dup = True
                    break
            if not is_dup:
                files_to_process.append((f, None)) # None ä»£è¡¨æ–°æª”æ¡ˆ

    # é¡¯ç¤º metadata è¡¨å–® (åªæœ‰ç•¶æœ‰æª”æ¡ˆè¦è™•ç†æ™‚)
    if files_to_process:
        st.divider()
        st.info(f"æº–å‚™è™•ç† {len(files_to_process)} å€‹æª”æ¡ˆ")
        
        with st.form("upload_meta_form"):
            col_m1, col_m2, col_m3 = st.columns(3)
            with col_m1:
                u_type = st.selectbox("è€ƒè©¦é¡å‹", ["å­¸æ¸¬", "åˆ†ç§‘", "åŒ—æ¨¡", "ä¸­æ¨¡", "å…¨æ¨¡", "å…¶ä»–"])
            with col_m2:
                u_year = st.text_input("å¹´åº¦ (ä¾‹å¦‚ 112)", value="112")
            with col_m3:
                u_exam_no = st.selectbox("è€ƒè©¦æ¬¡åˆ¥", ["ç¬¬ä¸€æ¬¡", "ç¬¬äºŒæ¬¡", "ç¬¬ä¸‰æ¬¡", "æ­£å¼è€ƒè©¦"])
            
            submitted = st.form_submit_button("ç¢ºèªä¸Šå‚³")
            
            if submitted:
                success_count = 0
                progress_bar = st.progress(0)
                
                for idx, (f, old_id) in enumerate(files_to_process):
                    file_bytes = f.read()
                    f.seek(0) # é‡ç½®æŒ‡æ¨™ï¼Œç¢ºä¿è®€å–æ­£ç¢º
                    
                    # 1. ä¸Šå‚³ Storage (è¦†è“‹åŒåæª”æ¡ˆ)
                    backup_url = cloud_manager.upload_bytes(
                        file_bytes, 
                        f.name, 
                        folder="raw_uploads", 
                        content_type=f.type
                    )
                    
                    # 2. å¯«å…¥/æ›´æ–° Firestore
                    file_record = {
                        "filename": f.name,
                        "url": backup_url,
                        "exam_type": u_type,
                        "year": u_year,
                        "exam_no": u_exam_no,
                        "ai_status": "æœªè¾¨è­˜", # é‡æ–°ä¸Šå‚³å¾Œç‹€æ…‹é‡ç½®
                    }
                    
                    # å¦‚æœæ˜¯è¦†è“‹ï¼Œsave_file_record æœƒä½¿ç”¨ old_id
                    cloud_manager.save_file_record(file_record, overwrite_id=old_id)
                    
                    # 3. åŠ å…¥æœ¬åœ°æš«å­˜
                    st.session_state['file_queue'][f.name] = {
                        "status": "uploaded", 
                        "data": file_bytes,
                        "type": f.name.split('.')[-1].lower(),
                        "result": [],
                        "error_msg": "",
                        "source_tag": f"{u_type}-{u_year}",
                        "backup_url": backup_url,
                    }
                    success_count += 1
                    progress_bar.progress((idx + 1) / len(files_to_process))
                
                if success_count > 0:
                    st.success(f"å·²æˆåŠŸè™•ç† {success_count} å€‹æª”æ¡ˆï¼")
                    time.sleep(1)
                    st.rerun()

# === Tab 3: åŒ¯å…¥æ ¡å° ===
with tab_review:
    st.subheader("åŒ¯å…¥æ ¡å°èˆ‡æˆªåœ–")
    ready_files = [f for f, info in st.session_state['file_queue'].items() if info['status'] == 'done']
    
    if not ready_files:
        st.warning("æ²’æœ‰å·²å®Œæˆè¾¨è­˜çš„æª”æ¡ˆã€‚è«‹å…ˆè‡³ã€Œæª”æ¡ˆåº«ç®¡ç†ã€é»æ“Šè¾¨è­˜ï¼Œæˆ–ä¸Šå‚³æ–°æª”æ¡ˆã€‚")
    else:
        selected_file = st.selectbox("é¸æ“‡è¦è™•ç†çš„æª”æ¡ˆ", ready_files)
        file_info = st.session_state['file_queue'][selected_file]
        candidates = file_info['result']
        
        st.markdown(f"**æ­£åœ¨ç·¨è¼¯ï¼š{selected_file} (å…± {len(candidates)} é¡Œ)**")
        col_src1, col_src2 = st.columns(2)
        with col_src1:
            default_tag = file_info.get("source_tag", "æœªåˆ†é¡")
            source_tag = st.text_input("è¨­å®šæ­¤æ‰¹è©¦å·ä¾†æºæ¨™ç±¤", value=default_tag)
        
        st.divider()
        
        with st.form(key=f"edit_form_{selected_file}"):
            for i, cand in enumerate(candidates):
                st.markdown(f"**ç¬¬ {cand.number} é¡Œ**")
                c1, c2 = st.columns([1, 1])
                with c1:
                    cand.content = st.text_area(f"é¡Œç›®å…§å®¹ #{i}", cand.content, height=100, key=f"{selected_file}_c_{i}")
                    opts_text = "\n".join(cand.options)
                    new_opts = st.text_area(f"é¸é … #{i}", opts_text, height=80, key=f"{selected_file}_o_{i}")
                    cand.options = new_opts.split('\n') if new_opts else []
                    type_idx = ["Single", "Multi", "Fill"].index(cand.q_type) if cand.q_type in ["Single", "Multi", "Fill"] else 0
                    cand.q_type = st.selectbox(f"é¡Œå‹ #{i}", ["Single", "Multi", "Fill"], index=type_idx, key=f"{selected_file}_t_{i}")
                    ans_key = f"{selected_file}_ans_{i}"
                    default_ans = st.session_state.get(ans_key, "")
                    st.text_input(f"ç­”æ¡ˆ (å¯ç•™ç©º) #{i}", value=default_ans, key=ans_key)
                    chap_idx = 0
                    if cand.predicted_chapter in smart_importer.PHYSICS_CHAPTERS_LIST:
                        chap_idx = smart_importer.PHYSICS_CHAPTERS_LIST.index(cand.predicted_chapter)
                    cand.predicted_chapter = st.selectbox(f"ç« ç¯€åˆ†é¡ #{i}", smart_importer.PHYSICS_CHAPTERS_LIST, index=chap_idx, key=f"{selected_file}_ch_{i}")
                    if cand.image_bytes: st.image(cand.image_bytes, caption="ç›®å‰é™„åœ–", width=200)
                    else: st.caption("ğŸš« ç›®å‰ç„¡é™„åœ–")

                with c2:
                    st.markdown("âœ‚ï¸ **æˆªåœ–å·¥å…·**")
                    image_to_crop = cand.ref_image_bytes if cand.ref_image_bytes else cand.full_page_bytes
                    if image_to_crop:
                        try:
                            pil_ref = Image.open(io.BytesIO(image_to_crop))
                            st_cropper(
                                pil_ref, realtime_update=True, box_color='#FF0000',
                                key=f"{selected_file}_cropper_{i}", aspect_ratio=None
                            )
                            st.caption("æç¤ºï¼šæˆªåœ–éœ€åœ¨ Form æäº¤å¾Œæˆ–ç¨ç«‹æ“ä½œ")
                        except: st.error("æˆªåœ–è¼‰å…¥å¤±æ•—")
                    else:
                        st.info("ç„¡æ³•å–å¾—æ­¤é¡Œçš„åƒè€ƒåœ–ç‰‡ (ä¹Ÿç„¡æ•´é åœ–ç‰‡)")
                st.divider()
            
            st.form_submit_button("ğŸ’¾ æš«å­˜æ‰€æœ‰ä¿®æ”¹ (ä¸æœƒä¸Šå‚³)")
        
        if st.button(f"âœ… ç¢ºèªåŒ¯å…¥ [{selected_file}] è‡³é›²ç«¯", type="primary"):
            progress_bar = st.progress(0)
            count = 0
            total = len(candidates)
            db_file_id = file_info.get("db_id")

            for i, cand in enumerate(candidates):
                ans_val = st.session_state.get(f"{selected_file}_ans_{i}", "")
                new_q = Question(
                    q_type=cand.q_type,
                    content=cand.content,
                    options=cand.options,
                    source=source_tag, 
                    chapter=cand.predicted_chapter,
                    image_data=cand.image_bytes,
                    answer=ans_val,
                    source_file_id=db_file_id
                )
                cloud_manager.save_question(new_q.to_dict())
                st.session_state['question_pool'].append(new_q)
                count += 1
                progress_bar.progress((i + 1) / total)
            
            st.success(f"æˆåŠŸåŒ¯å…¥ {count} é¡Œï¼")
            st.session_state['file_queue'][selected_file]['status'] = 'imported'
            if db_file_id:
                cloud_manager.update_file_status(db_file_id, "å·²åŒ¯å…¥")
            st.rerun()

# === Tab 4: é¡Œåº«ç®¡ç† ===
with tab_bank:
    st.subheader("é¡Œåº«ç¸½è¦½èˆ‡è©¦å·è¼¸å‡º")
    if not st.session_state['question_pool']:
        st.info("ç›®å‰æ²’æœ‰é¡Œç›®ã€‚")
    else:
        all_sources = sorted(list(set([q.source for q in st.session_state['question_pool']])))
        selected_questions_for_export = []
        for src in all_sources:
            qs_in_src = [q for q in st.session_state['question_pool'] if q.source == src]
            with st.expander(f"ğŸ“ {src} ({len(qs_in_src)} é¡Œ)"):
                if st.checkbox(f"é¸å–å…¨å¥— [{src}] é€²è¡ŒåŒ¯å‡º", key=f"sel_src_{src}"):
                    selected_questions_for_export.extend(qs_in_src)
                for i, q in enumerate(qs_in_src):
                    type_badge = {'Single': 'å–®', 'Multi': 'å¤š', 'Fill': 'å¡«', 'Group': 'é¡Œçµ„'}.get(q.type, 'æœªçŸ¥')
                    if q.parent_id: continue 
                    st.markdown(f"**[{type_badge}] {q.content[:30]}...**")
                    if q.image_url: st.caption("ğŸ–¼ï¸ é›²ç«¯åœ–ç‰‡")
                    elif q.image_data: st.caption("ğŸ’¾ æœ¬æ©Ÿåœ–ç‰‡ (æœªåŒæ­¥)")
                    with st.popover("ç·¨è¼¯"):
                        q.content = st.text_area("é¡Œç›®", q.content, key=f"edt_c_{q.id}")
                        q.answer = st.text_input("ç­”æ¡ˆ", q.answer, key=f"edt_a_{q.id}")
                        if st.button("å„²å­˜", key=f"save_{q.id}"):
                            cloud_manager.save_question(q.to_dict())
                            st.rerun()
                        if st.button("åˆªé™¤", key=f"del_{q.id}", type="primary"):
                            cloud_manager.delete_question(q.id)
                            st.rerun()
                    st.divider()

        st.divider()
        st.subheader(f"å·²é¸å– {len(selected_questions_for_export)} é¡Œæº–å‚™åŒ¯å‡º")
        if st.button("ç”Ÿæˆ Word è©¦å·"):
            f1, f2 = generate_word_files(selected_questions_for_export)
            st.download_button("ä¸‹è¼‰è©¦é¡Œå·", f1, "exam.docx")
            st.download_button("ä¸‹è¼‰ç­”æ¡ˆå·", f2, "ans.docx")
